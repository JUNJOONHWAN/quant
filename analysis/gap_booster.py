#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gemini ê°­í•„í„° ë¶€ìŠ¤í„°
AI ë…ë¦½ íŒë‹¨ vs ì‹¤ì œ VTNF ë¸íƒ€ ë¶„ì„
"""
import re
import json
import asyncio
import aiohttp
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Tuple
import logging

logger = logging.getLogger(__name__)

class GeminiGapFilterBooster:
    """Gemini Flashë¡œ VTNF ê°­ ë¶„ì„ (AI ë…ë¦½ íŒë‹¨ vs ì‹¤ì œ VTNF ë¸íƒ€)"""

    def __init__(self, api_manager):
        self.api_manager = api_manager
        self.gap_cache = {}  # 10ë¶„ê°„ ìºì‹±
        self.cache_duration = timedelta(minutes=10)
        
        # ê°­ ì„ê³„ê°’ ì„¤ì •
        self.gap_thresholds = {
            'minor': 0.5,     # ì‘ì€ ê°­
            'moderate': 1.0,  # ì¤‘ê°„ ê°­
            'major': 1.5,     # í° ê°­
            'extreme': 2.0    # ê·¹ë‹¨ì  ê°­
        }
        
        # ë¶€ìŠ¤íŠ¸ ê°•ë„ ì„¤ì •
        self.boost_settings = {
            'max_boost': 2.0,      # ìµœëŒ€ ë¶€ìŠ¤íŠ¸
            'confidence_weight': 0.3,  # ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜
            'delta_weight': 0.4,       # ë¸íƒ€ ê°€ì¤‘ì¹˜
            'comprehensive_weight': 0.3  # ì¢…í•© íŒë‹¨ ê°€ì¤‘ì¹˜
        }
        
        logger.info("ğŸ¯ Gemini ê°­í•„í„° ë¶€ìŠ¤í„° ì´ˆê¸°í™” ì™„ë£Œ")

    async def calculate_vtnf_gap_boost(self, symbol: str, vtnf_scores: dict) -> dict:
        """âœ… AI ë…ë¦½ íŒë‹¨ vs VTNF ì‹¤ì œê°’ ë¸íƒ€ ê³„ì‚°"""
        try:
            logger.info(f"ğŸ¯ {symbol} AI ë¸íƒ€ ê°­í•„í„° ë¶„ì„ ì‹œì‘...")
            
            # ìºì‹œ í™•ì¸
            cache_key = f"{symbol}_gap_{datetime.now().strftime('%H:%M')[:-1]}0"
            if cache_key in self.gap_cache:
                cached_time, cached_result = self.gap_cache[cache_key]
                if datetime.now() - cached_time < self.cache_duration:
                    logger.info(f"ğŸ“‹ {symbol} ê°­ ë¶„ì„ ìºì‹œ ì‚¬ìš©")
                    return cached_result

            # 1. âœ… AIì˜ ë…ë¦½ì ì¸ ì¢…í•© íŒë‹¨ (ì„¹í„° ë¬´ê´€)
            ai_comprehensive_query = self._build_comprehensive_query(symbol)
            
            # 2. âœ… AIì˜ ê°œë³„ VTNF ì˜ˆì¸¡ (ì‹¤ì œê°’ê³¼ ë¹„êµìš©)
            ai_vtnf_predictions = self._build_vtnf_prediction_queries(symbol)
            
            # 3. ë³‘ë ¬ API í˜¸ì¶œ
            comprehensive_task = self._get_ai_score(ai_comprehensive_query)
            prediction_tasks = {k: self._get_ai_score(v) for k, v in ai_vtnf_predictions.items()}
            
            # ê²°ê³¼ ìˆ˜ì§‘
            ai_comprehensive = await comprehensive_task
            ai_predictions = {}
            for k, task in prediction_tasks.items():
                ai_predictions[k.lower()] = await task
                
            # 4. âœ… ì‹¤ì œ VTNF ê°’ ì •ê·œí™” (ì†Œë¬¸ìë¡œ í†µì¼)
            actual_vtnf = {k.lower(): float(v) for k, v in vtnf_scores.items() if v is not None}
            
            # 5. âœ… ë¸íƒ€ ê³„ì‚° (AI ì˜ˆì¸¡ - ì‹¤ì œê°’)
            deltas = {}
            total_delta = 0
            valid_factors = 0
            
            for factor in ['v', 't', 'n', 'f']:
                if factor in actual_vtnf and factor in ai_predictions:
                    predicted = float(ai_predictions[factor])
                    actual = float(actual_vtnf[factor])
                    delta = predicted - actual
                    deltas[factor] = delta
                    total_delta += delta
                    valid_factors += 1
                else:
                    deltas[factor] = 0.0
                    
            avg_delta = total_delta / max(valid_factors, 1)
            
            # 6. âœ… AI ì¢…í•© íŒë‹¨ vs VTNF í‰ê· ì˜ ê°­
            actual_vtnf_avg = sum(actual_vtnf.values()) / max(len(actual_vtnf), 1)
            comprehensive_gap = ai_comprehensive - actual_vtnf_avg
            
            # 7. âœ… í†µí•© ê°­ ìŠ¤ì½”ì–´ ê³„ì‚°
            # AIê°€ ê°œë³„ ìš”ì†Œë“¤ì„ ë‹¤ë¥´ê²Œ ë³´ëŠ” ì •ë„(ë¸íƒ€) + ì¢…í•© íŒë‹¨ì˜ ì°¨ì´
            integrated_gap = (comprehensive_gap * 0.6) + (avg_delta * 0.4)
            
            # ë¡œê¹…
            logger.info(f"ğŸ” {symbol} AI ë¸íƒ€ ë¶„ì„:")
            logger.info(f"   AI ì¢…í•© íŒë‹¨: {ai_comprehensive}")
            logger.info(f"   ì‹¤ì œ VTNF í‰ê· : {actual_vtnf_avg:.2f}")
            logger.info(f"   ì¢…í•© ê°­: {comprehensive_gap:+.2f}")
            logger.info(f"   AI ì˜ˆì¸¡ VTNF: {ai_predictions}")
            logger.info(f"   ì‹¤ì œ VTNF: {actual_vtnf}")
            logger.info(f"   ë¸íƒ€: {deltas}")
            logger.info(f"   í‰ê·  ë¸íƒ€: {avg_delta:+.2f}")
            logger.info(f"   í†µí•© ê°­: {integrated_gap:+.2f}")
            
            # 8. âœ… ê°­ ìœ ì˜ì„± í‰ê°€
            gap_significance = self._evaluate_gap_significance(
                integrated_gap, comprehensive_gap, avg_delta, deltas
            )
            
            # 9. âœ… ë¶€ìŠ¤íŠ¸ ê²°ì •
            result = self._calculate_boost_result(
                symbol, integrated_gap, comprehensive_gap, avg_delta, deltas,
                gap_significance, ai_comprehensive, ai_predictions, actual_vtnf
            )
            
            # ìºì‹œ ì €ì¥
            self.gap_cache[cache_key] = (datetime.now(), result)
            
            return result
                
        except Exception as e:
            logger.error(f"âŒ {symbol} AI ë¸íƒ€ ê°­í•„í„° ì‹¤íŒ¨: {e}")
            return self._get_error_result(symbol, str(e))

    def _build_comprehensive_query(self, symbol: str) -> str:
        """ì¢…í•© íŒë‹¨ ì¿¼ë¦¬ êµ¬ì„±"""
        return f"""
You are an elite institutional portfolio manager analyzing {symbol} with complete independence from sector classifications.

**COMPREHENSIVE INVESTMENT ANALYSIS**

Analyze {symbol} based on its unique characteristics, not sector stereotypes:

**Company-Specific Dynamics**
- What unique business model or strategic positioning does {symbol} have?
- How does it differ from typical companies in its sector?
- What company-specific catalysts or risks exist?

**Cross-Sector Opportunities**
- Does {symbol} operate across multiple sectors or have hybrid characteristics?
- Are there technology/innovation elements regardless of sector classification?
- What non-traditional revenue streams or growth drivers exist?

**Market Perception vs Reality**
- Is the market categorizing this company correctly?
- What aspects might algorithmic trading or sector ETFs be missing?
- Are there hidden value drivers the market overlooks?

**Adaptive Scoring Framework**
Instead of sector-based analysis, evaluate based on:
- Innovation & Disruption Potential (regardless of sector)
- Execution & Management Quality
- Market Position & Competitive Moat
- Financial Flexibility & Capital Efficiency
- Catalyst Timing & Momentum

**INDEPENDENT CONVICTION SCORE (0-10):**
Rate {symbol} purely on its individual merits, ignoring sector conventions.
Consider how this specific company might surprise the market.

CONVICTION SCORE: [0-10]
"""

    def _build_vtnf_prediction_queries(self, symbol: str) -> dict:
        """VTNF ì˜ˆì¸¡ ì¿¼ë¦¬ êµ¬ì„±"""
        return {
            'V': f"""Analyze {symbol}'s FUNDAMENTAL VALUE ignoring sector norms.
Consider: unique financial metrics, hidden assets, cash generation ability, 
non-traditional value drivers specific to this company.
Look at P/E ratios, revenue growth, profit margins, debt levels, but focus on 
what makes THIS company different from sector averages.
PREDICTED V SCORE (0-10):""",
            
            'T': f"""Analyze {symbol}'s TECHNICAL DYNAMICS beyond sector patterns.
Consider: unique price behavior, volume anomalies, algorithmic trading patterns,
company-specific technical setups that differ from sector.
Evaluate moving averages, RSI, MACD, volume patterns specific to this stock.
PREDICTED T SCORE (0-10):""",
            
            'N': f"""Analyze {symbol}'s NEWS & SENTIMENT with fresh perspective.
Consider: company-specific catalysts, management changes, product launches,
partnerships that transcend typical sector news flow.
Recent earnings, analyst upgrades/downgrades, industry disruption potential.
PREDICTED N SCORE (0-10):""",
            
            'F': f"""Analyze {symbol}'s INSTITUTIONAL FLOWS independently.
Consider: smart money movements specific to this stock, unusual options activity,
insider behavior that differs from sector trends.
ETF flows, hedge fund positions, institutional ownership changes.
PREDICTED F SCORE (0-10):"""
        }

    async def _get_ai_score(self, query: str) -> float:
        """AI API í˜¸ì¶œí•˜ì—¬ ì ìˆ˜ ì¶”ì¶œ"""
        try:
            gemini_config = self.api_manager.get_gemini_config()
            api_key = gemini_config['api_key']
            base_url = gemini_config['base_url']
            
            if not api_key or api_key == 'GEM':
                logger.warning("Gemini API í‚¤ ì—†ìŒ, ê¸°ë³¸ê°’ ë°˜í™˜")
                return 6.0
            
            url = f"{base_url}/models/gemini-2.0-flash-exp:generateContent"
            headers = {
                "Content-Type": "application/json",
                "x-goog-api-key": api_key
            }
            
            payload = {
                "contents": [{
                    "parts": [{"text": query}]
                }],
                "generationConfig": {
                    "temperature": 0.1,
                    "topK": 1,
                    "topP": 0.1,
                    "maxOutputTokens": 200
                }
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, headers=headers, timeout=15) as response:
                    if response.status == 200:
                        result = await response.json()
                        content = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '')
                        
                        # ì ìˆ˜ ì¶”ì¶œ
                        score = self._extract_score_from_text(content)
                        return score
                    else:
                        logger.warning(f"Gemini API ì˜¤ë¥˜: {response.status}")
                        return 6.0
                        
        except Exception as e:
            logger.warning(f"AI ì ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 6.0

    def _extract_score_from_text(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ì—ì„œ ì ìˆ˜ ì¶”ì¶œ"""
        try:
            # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ì ìˆ˜ ì¶”ì¶œ ì‹œë„
            patterns = [
                r'CONVICTION SCORE:\s*(\d+(?:\.\d+)?)',
                r'PREDICTED [VTNF] SCORE.*?(\d+(?:\.\d+)?)',
                r'SCORE.*?(\d+(?:\.\d+)?)',
                r'(\d+(?:\.\d+)?)/10',
                r'(\d+(?:\.\d+)?)\s*ì ',
                r'(\d+(?:\.\d+)?)\s*out of 10'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    score = float(matches[0])
                    # ì ìˆ˜ ë²”ìœ„ ê²€ì¦ ë° ì •ê·œí™”
                    if 0 <= score <= 10:
                        return score
                    elif score > 10:
                        return min(score / 10, 10.0) if score <= 100 else 10.0
            
            # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ìˆ«ìë§Œ ì¶”ì¶œ
            numbers = re.findall(r'\b(\d+(?:\.\d+)?)\b', text)
            for num_str in numbers:
                num = float(num_str)
                if 0 <= num <= 10:
                    return num
                elif 10 < num <= 100:
                    return num / 10
            
            # ê¸°ë³¸ê°’
            return 6.0
            
        except Exception as e:
            logger.warning(f"ì ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 6.0

    def _evaluate_gap_significance(self, integrated_gap: float, comprehensive_gap: float, 
                                  avg_delta: float, deltas: dict) -> dict:
        """ê°­ ìœ ì˜ì„± í‰ê°€"""
        try:
            # 1. ê°­ í¬ê¸° í‰ê°€
            abs_integrated_gap = abs(integrated_gap)
            abs_comprehensive_gap = abs(comprehensive_gap)
            abs_avg_delta = abs(avg_delta)
            
            # 2. ì„ê³„ê°’ ê¸°ë°˜ ë¶„ë¥˜
            gap_level = 'minor'
            if abs_integrated_gap >= self.gap_thresholds['extreme']:
                gap_level = 'extreme'
            elif abs_integrated_gap >= self.gap_thresholds['major']:
                gap_level = 'major'
            elif abs_integrated_gap >= self.gap_thresholds['moderate']:
                gap_level = 'moderate'
            
            # 3. ì¼ê´€ì„± í‰ê°€ (ëª¨ë“  ë¸íƒ€ê°€ ê°™ì€ ë°©í–¥ì¸ì§€)
            delta_values = [v for v in deltas.values() if v != 0]
            if delta_values:
                positive_deltas = sum(1 for d in delta_values if d > 0)
                negative_deltas = sum(1 for d in delta_values if d < 0)
                consistency = abs(positive_deltas - negative_deltas) / len(delta_values)
            else:
                consistency = 0
            
            # 4. ì‹ ë¢°ë„ ê³„ì‚°
            confidence = min(
                (abs_integrated_gap / self.gap_thresholds['moderate']) * 0.4 +
                consistency * 0.3 +
                (min(abs_comprehensive_gap, 2.0) / 2.0) * 0.3,
                1.0
            )
            
            # 5. ìœ ì˜ì„± íŒë‹¨
            is_significant = (
                abs_integrated_gap >= self.gap_thresholds['minor'] and
                confidence >= 0.3
            )
            
            # 6. ê°­ ê°•ë„ ê³„ì‚°
            strength = min(abs_integrated_gap, self.boost_settings['max_boost'])
            
            # 7. ë°œì‚° ìš”ì†Œ ë¶„ì„
            divergence_factors = []
            if abs_comprehensive_gap > 1.0:
                divergence_factors.append('ì¢…í•©_íŒë‹¨_ì°¨ì´')
            if abs_avg_delta > 0.8:
                divergence_factors.append('ê°œë³„_ìš”ì†Œ_ì°¨ì´')
            if consistency > 0.7:
                divergence_factors.append('ì¼ê´€ëœ_ë°©í–¥ì„±')
            
            return {
                'is_significant': is_significant,
                'gap_level': gap_level,
                'strength': strength,
                'confidence': confidence,
                'consistency': consistency,
                'divergence_factors': divergence_factors
            }
            
        except Exception as e:
            logger.error(f"ê°­ ìœ ì˜ì„± í‰ê°€ ì‹¤íŒ¨: {e}")
            return {
                'is_significant': False,
                'gap_level': 'minor',
                'strength': 0,
                'confidence': 0,
                'consistency': 0,
                'divergence_factors': []
            }

    def _calculate_position_adjustment(self, integrated_gap: float, boost_strength: float, 
                                     confidence: float) -> float:
        """í¬ì§€ì…˜ ì¡°ì • ë¹„ìœ¨ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ ì¡°ì • ë¹„ìœ¨
            base_adjustment = integrated_gap * 10  # -20 ~ +20 ë²”ìœ„
            
            # ì‹ ë¢°ë„ì™€ ê°•ë„ë¡œ ì¡°ì •
            confidence_factor = confidence ** 0.5
            strength_factor = min(boost_strength / self.boost_settings['max_boost'], 1.0)
            
            # ìµœì¢… ì¡°ì • ë¹„ìœ¨
            position_adjustment = base_adjustment * confidence_factor * strength_factor
            
            # ë²”ìœ„ ì œí•œ (-30% ~ +30%)
            return max(-30, min(30, position_adjustment))
            
        except Exception as e:
            logger.error(f"í¬ì§€ì…˜ ì¡°ì • ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0

    def _calculate_boost_result(self, symbol: str, integrated_gap: float, comprehensive_gap: float,
                               avg_delta: float, deltas: dict, gap_significance: dict,
                               ai_comprehensive: float, ai_predictions: dict, actual_vtnf: dict) -> dict:
        """ë¶€ìŠ¤íŠ¸ ê²°ê³¼ ê³„ì‚°"""
        try:
            if gap_significance['is_significant']:
                boost_type = 'synergy' if integrated_gap > 0 else 'risk'
                boost_strength = gap_significance['strength']
                position_adjustment = self._calculate_position_adjustment(
                    integrated_gap, boost_strength, gap_significance['confidence']
                )
                
                return {
                    'gap_detected': True,
                    'gap_score': round(integrated_gap, 2),
                    'integrated_gap': round(integrated_gap, 2),
                    'comprehensive_gap': round(comprehensive_gap, 2),
                    'avg_delta': round(avg_delta, 2),
                    'deltas': {k: round(v, 2) for k, v in deltas.items()},
                    'boost_type': boost_type,
                    'boost_strength': round(boost_strength, 2),
                    'position_adjustment': round(position_adjustment, 1),
                    'ai_comprehensive': ai_comprehensive,
                    'ai_predictions': ai_predictions,
                    'actual_vtnf': actual_vtnf,
                    'confidence': gap_significance['confidence'],
                    'gap_level': gap_significance['gap_level'],
                    'consistency': gap_significance['consistency'],
                    'divergence_factors': gap_significance['divergence_factors'],
                    'method': 'ai_independent_delta',
                    'timestamp': datetime.now().isoformat()
                }
            else:
                return {
                    'gap_detected': False,
                    'gap_score': round(integrated_gap, 2),
                    'integrated_gap': round(integrated_gap, 2),
                    'comprehensive_gap': round(comprehensive_gap, 2),
                    'avg_delta': round(avg_delta, 2),
                    'deltas': {k: round(v, 2) for k, v in deltas.items()},
                    'boost_type': 'neutral',
                    'boost_strength': 0,
                    'position_adjustment': 0,
                    'confidence': gap_significance['confidence'],
                    'gap_level': gap_significance['gap_level'],
                    'method': 'ai_independent_delta',
                    'timestamp': datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"ë¶€ìŠ¤íŠ¸ ê²°ê³¼ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return self._get_error_result(symbol, str(e))

    def _get_error_result(self, symbol: str, error_msg: str) -> dict:
        """ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜"""
        return {
            'gap_detected': False,
            'gap_score': 0,
            'integrated_gap': 0,
            'comprehensive_gap': 0,
            'avg_delta': 0,
            'deltas': {'v': 0, 't': 0, 'n': 0, 'f': 0},
            'boost_type': 'error',
            'boost_strength': 0,
            'position_adjustment': 0,
            'confidence': 0,
            'gap_level': 'none',
            'error': error_msg,
            'method': 'ai_independent_delta',
            'timestamp': datetime.now().isoformat()
        }

    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        current_time = datetime.now()
        expired_keys = []
        
        for key, (timestamp, _) in self.gap_cache.items():
            if current_time - timestamp > self.cache_duration:
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.gap_cache[key]
        
        logger.info(f"ğŸ§¹ ê°­ ë¶€ìŠ¤í„° ìºì‹œ ì •ë¦¬: {len(expired_keys)}ê°œ í•­ëª© ì‚­ì œ")

    def get_cache_stats(self) -> dict:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        return {
            'total_entries': len(self.gap_cache),
            'cache_duration_minutes': self.cache_duration.total_seconds() / 60,
            'gap_thresholds': self.gap_thresholds,
            'boost_settings': self.boost_settings
        }
