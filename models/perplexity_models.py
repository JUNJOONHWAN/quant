#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í¼í”Œë ‰ì‹œí‹° ëª¨ë¸ ê´€ë¦¬ì
Perplexity API ëª¨ë¸ í†µí•© ê´€ë¦¬ - ë”¥ë¦¬ì„œì¹˜ í¬í•¨
"""
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)

@dataclass
class PerplexityModel:
    """í¼í”Œë ‰ì‹œí‹° ëª¨ë¸ ì •ë³´"""
    api_model: str
    display_name: str
    category: str
    context_length: int
    max_output_tokens: int
    model_type: str
    features: List[str]
    pricing_tier: str
    description: str
    use_cases: List[str]
    recommended: bool = False
    deprecated: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)

class PerplexityModelManager:
    """í¼í”Œë ‰ì‹œí‹° API ëª¨ë¸ í†µí•© ê´€ë¦¬ - ë”¥ë¦¬ì„œì¹˜ í¬í•¨"""

    def __init__(self):
        self.models = self._initialize_models()
        self.model_groups = self._group_models()
        self.default_model = "sonar-pro"
        self.fallback_model = "sonar"
        
        logger.info(f"ğŸ” Perplexity ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”: {len(self.models)}ê°œ ëª¨ë¸")

    def _initialize_models(self) -> Dict[str, PerplexityModel]:
        """2025ë…„ 6ì›” ìµœì‹  Perplexity ëª¨ë¸ ì •ì˜"""
        models = {}
        
        # ğŸ” Sonar Models (í•µì‹¬ ê²€ìƒ‰ ëª¨ë¸ë“¤)
        models["sonar-pro"] = PerplexityModel(
            api_model="sonar-pro",
            display_name="ğŸš€ Sonar Pro (ê²€ìƒ‰ + ë³µì¡ ì¿¼ë¦¬)",
            category="sonar",
            context_length=200000,  # 200k tokens
            max_output_tokens=8000,
            model_type="Chat Completion",
            features=["web_search", "real_time_data", "advanced_reasoning"],
            pricing_tier="premium",
            description="ë³µì¡í•œ ì¿¼ë¦¬ì™€ ê¹Šì€ ì½˜í…ì¸  ì´í•´ì— ìµœì í™”ëœ ê³ ê¸‰ ê²€ìƒ‰ ëª¨ë¸",
            use_cases=[
                "ì‹¬í™” ì‹œì¥ ë¶„ì„", "ë³µí•© ë°ì´í„° ê²€ìƒ‰", "ì „ë¬¸ê°€ ìˆ˜ì¤€ ë¦¬ì„œì¹˜",
                "ë‹¤ê°ë„ ì •ë³´ ì¢…í•©", "íŠ¸ë Œë“œ ë¶„ì„"
            ],
            recommended=True
        )
        
        models["sonar"] = PerplexityModel(
            api_model="sonar",
            display_name="âš¡ Sonar (ê²½ëŸ‰ ê²€ìƒ‰)",
            category="sonar",
            context_length=128000,  # 128k tokens
            max_output_tokens=4000,
            model_type="Chat Completion",
            features=["web_search", "real_time_data"],
            pricing_tier="standard",
            description="ë¹ ë¥´ê³  ë¹„ìš© íš¨ìœ¨ì ì¸ ê²½ëŸ‰ ê²€ìƒ‰ ëª¨ë¸",
            use_cases=[
                "ê¸°ë³¸ ì •ë³´ ê²€ìƒ‰", "ë‰´ìŠ¤ ìš”ì•½", "ë¹ ë¥¸ íŒ©íŠ¸ ì²´í¬",
                "ì¼ë°˜ì ì¸ ì§ˆì˜ì‘ë‹µ", "ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ"
            ],
            recommended=False
        )

        # ğŸ“Š Deep Research Model (í•µì‹¬)
        models["sonar-deep-research"] = PerplexityModel(
            api_model="sonar-deep-research",
            display_name="ğŸ“Š Sonar Deep Research (ì‹¬í™” ì—°êµ¬)",
            category="deep_research",
            context_length=128000,
            max_output_tokens=8000,
            model_type="Deep Research",
            features=["deep_analysis", "comprehensive_reports", "multi_source_synthesis"],
            pricing_tier="premium",
            description="ìƒì„¸í•œ ë³´ê³ ì„œì™€ ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸ ìƒì„±ì— ìµœì í™”",
            use_cases=[
                "ì¢…í•© íˆ¬ì ë¶„ì„", "ì‹œì¥ ì‹¬í™” ë¦¬ì„œì¹˜", "ê²½ìŸì‚¬ ë¶„ì„",
                "ì—…ê³„ íŠ¸ë Œë“œ ë³´ê³ ì„œ", "ì „ëµì  ì˜ì‚¬ê²°ì • ì§€ì›"
            ],
            recommended=True
        )

        # ğŸ§  Reasoning Models (ì¶”ë¡  íŠ¹í™”)
        models["sonar-reasoning-pro"] = PerplexityModel(
            api_model="sonar-reasoning-pro",
            display_name="ğŸ§  Sonar Reasoning Pro (ê³ ê¸‰ ì¶”ë¡ )",
            category="reasoning",
            context_length=128000,
            max_output_tokens=8000,
            model_type="Chain of Thought",
            features=["advanced_reasoning", "step_by_step_analysis", "logical_deduction"],
            pricing_tier="premium",
            description="ë³µì¡í•œ ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ë‹¨ê³„ë³„ ë¶„ì„ì— íŠ¹í™”",
            use_cases=[
                "ë³µí•© íˆ¬ì ì „ëµ ìˆ˜ë¦½", "ë¦¬ìŠ¤í¬ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„", 
                "ë…¼ë¦¬ì  ì˜ì‚¬ê²°ì • ì§€ì›", "ë³µì¡í•œ ë¬¸ì œ í•´ê²°"
            ]
        )

        models["sonar-reasoning"] = PerplexityModel(
            api_model="sonar-reasoning",
            display_name="ğŸ” Sonar Reasoning (ê¸°ë³¸ ì¶”ë¡ )",
            category="reasoning",
            context_length=128000,
            max_output_tokens=4000,
            model_type="Chain of Thought",
            features=["basic_reasoning", "step_by_step_analysis"],
            pricing_tier="standard",
            description="ê¸°ë³¸ì ì¸ ì¶”ë¡ ê³¼ ë‹¨ê³„ë³„ ë¶„ì„ ì œê³µ",
            use_cases=[
                "ê¸°ë³¸ ë¶„ì„ ë…¼ë¦¬", "ë‹¨ê³„ë³„ ì„¤ëª…", "ì¶”ë¡  ê³¼ì • ì‹œê°í™”"
            ]
        )

        # ğŸ’¬ Chat Model (ì˜¤í”„ë¼ì¸)
        models["r1-1776"] = PerplexityModel(
            api_model="r1-1776",
            display_name="ğŸ’¬ R1-1776 (ì˜¤í”„ë¼ì¸ ì±„íŒ…)",
            category="chat",
            context_length=128000,
            max_output_tokens=4000,
            model_type="Chat Completion",
            features=["offline_chat", "no_web_search"],
            pricing_tier="standard",
            description="ì›¹ ê²€ìƒ‰ ì—†ëŠ” ìˆœìˆ˜ ëŒ€í™”í˜• ëª¨ë¸",
            use_cases=[
                "ì¼ë°˜ ëŒ€í™”", "í…ìŠ¤íŠ¸ ìƒì„±", "ì°½ì‘ ì§€ì›", "ì½”ë”© ë„ì›€"
            ]
        )

        return models

    def _group_models(self) -> Dict[str, List[str]]:
        """ëª¨ë¸ ê·¸ë£¹í•‘"""
        groups = {
            "recommended": [],
            "sonar": [],
            "deep_research": [],
            "reasoning": [],
            "chat": [],
            "premium": [],
            "standard": []
        }
        
        for model_id, model in self.models.items():
            if model.recommended:
                groups["recommended"].append(model_id)
            
            groups[model.category].append(model_id)
            groups[model.pricing_tier].append(model_id)
        
        return groups

    def get_model_info(self, model_id: str) -> Optional[PerplexityModel]:
        """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        return self.models.get(model_id)

    def get_recommended_models(self) -> List[PerplexityModel]:
        """ì¶”ì²œ ëª¨ë¸ ëª©ë¡"""
        return [
            self.models[model_id] 
            for model_id in self.model_groups["recommended"]
        ]

    def get_models_by_category(self, category: str) -> List[PerplexityModel]:
        """ì¹´í…Œê³ ë¦¬ë³„ ëª¨ë¸ ëª©ë¡"""
        return [
            self.models[model_id] 
            for model_id in self.model_groups.get(category, [])
        ]

    def get_best_model_for_task(self, task_type: str) -> str:
        """ì‘ì—… ìœ í˜•ë³„ ìµœì  ëª¨ë¸ ì¶”ì²œ"""
        task_models = {
            "deep_research": "sonar-deep-research",
            "market_analysis": "sonar-pro", 
            "news_sentiment": "sonar-pro",
            "quick_search": "sonar",
            "reasoning": "sonar-reasoning-pro",
            "chat": "r1-1776",
            "sector_analysis": "sonar-deep-research",
            "gap_analysis": "sonar-pro",
            "pattern_analysis": "sonar-reasoning"
        }
        
        return task_models.get(task_type, self.default_model)

    def validate_model(self, model_id: str) -> bool:
        """ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬"""
        return model_id in self.models

    def get_model_context_limit(self, model_id: str) -> int:
        """ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì¡°íšŒ"""
        model = self.models.get(model_id)
        return model.context_length if model else 128000

    def get_model_max_output(self, model_id: str) -> int:
        """ëª¨ë¸ ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜"""
        model = self.models.get(model_id)
        return model.max_output_tokens if model else 4000

    def estimate_cost_tier(self, model_id: str) -> str:
        """ë¹„ìš© ë“±ê¸‰ ì¶”ì •"""
        model = self.models.get(model_id)
        return model.pricing_tier if model else "standard"

    def get_model_features(self, model_id: str) -> List[str]:
        """ëª¨ë¸ ê¸°ëŠ¥ ëª©ë¡"""
        model = self.models.get(model_id)
        return model.features if model else []

    def has_web_search(self, model_id: str) -> bool:
        """ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì—¬ë¶€"""
        features = self.get_model_features(model_id)
        return "web_search" in features

    def has_deep_research(self, model_id: str) -> bool:
        """ë”¥ ë¦¬ì„œì¹˜ ê¸°ëŠ¥ ì—¬ë¶€"""
        features = self.get_model_features(model_id)
        return "deep_analysis" in features or "comprehensive_reports" in features

    def has_reasoning(self, model_id: str) -> bool:
        """ì¶”ë¡  ê¸°ëŠ¥ ì—¬ë¶€"""
        features = self.get_model_features(model_id)
        return any(f in features for f in ["advanced_reasoning", "basic_reasoning", "logical_deduction"])

    def get_fallback_model(self, preferred_model: str) -> str:
        """í´ë°± ëª¨ë¸ ì¶”ì²œ"""
        if not self.validate_model(preferred_model):
            return self.fallback_model
        
        model = self.models[preferred_model]
        
        # ê°™ì€ ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ í´ë°±
        category_models = self.get_models_by_category(model.category)
        if len(category_models) > 1:
            for fallback in category_models:
                if fallback.api_model != preferred_model and not fallback.deprecated:
                    return fallback.api_model
        
        return self.fallback_model

    def get_model_selection_guide(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ"""
        return {
            "quick_tasks": {
                "model": "sonar",
                "description": "ë¹ ë¥¸ ê²€ìƒ‰ê³¼ ê¸°ë³¸ ë¶„ì„",
                "suitable_for": ["ë‰´ìŠ¤ ìš”ì•½", "ê¸°ë³¸ ì •ë³´ ê²€ìƒ‰", "ë¹ ë¥¸ íŒ©íŠ¸ì²´í¬"]
            },
            "comprehensive_analysis": {
                "model": "sonar-pro", 
                "description": "ì¢…í•©ì ì¸ ë¶„ì„ê³¼ ë³µì¡í•œ ì¿¼ë¦¬",
                "suitable_for": ["ì‹œì¥ ë¶„ì„", "ë³µí•© ë°ì´í„° ê²€ìƒ‰", "ì „ë¬¸ê°€ ìˆ˜ì¤€ ë¦¬ì„œì¹˜"]
            },
            "deep_research": {
                "model": "sonar-deep-research",
                "description": "ì‹¬ì¸µ ì—°êµ¬ì™€ ìƒì„¸ ë³´ê³ ì„œ",
                "suitable_for": ["íˆ¬ì ë¶„ì„", "ê²½ìŸì‚¬ ë¶„ì„", "ì—…ê³„ íŠ¸ë Œë“œ ë¦¬í¬íŠ¸"]
            },
            "reasoning_tasks": {
                "model": "sonar-reasoning-pro",
                "description": "ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ë‹¨ê³„ë³„ ë¶„ì„", 
                "suitable_for": ["ì „ëµ ìˆ˜ë¦½", "ë¦¬ìŠ¤í¬ ë¶„ì„", "ë³µì¡í•œ ì˜ì‚¬ê²°ì •"]
            },
            "offline_chat": {
                "model": "r1-1776",
                "description": "ì›¹ ê²€ìƒ‰ ì—†ëŠ” ìˆœìˆ˜ ëŒ€í™”",
                "suitable_for": ["ì¼ë°˜ ëŒ€í™”", "í…ìŠ¤íŠ¸ ìƒì„±", "ì°½ì‘ ì§€ì›"]
            }
        }

    def get_usage_statistics(self) -> Dict[str, Any]:
        """ì‚¬ìš© í†µê³„ (ì‹œë®¬ë ˆì´ì…˜)"""
        return {
            "total_models": len(self.models),
            "recommended_models": len(self.model_groups["recommended"]),
            "categories": {
                category: len(models) 
                for category, models in self.model_groups.items()
                if category not in ["premium", "standard", "recommended"]
            },
            "pricing_tiers": {
                "premium": len(self.model_groups["premium"]),
                "standard": len(self.model_groups["standard"])
            },
            "features_coverage": {
                "web_search": len([m for m in self.models.values() if "web_search" in m.features]),
                "deep_analysis": len([m for m in self.models.values() if "deep_analysis" in m.features]),
                "reasoning": len([m for m in self.models.values() if any(f in m.features for f in ["advanced_reasoning", "basic_reasoning"])])
            }
        }

    def export_models_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë‚´ë³´ë‚´ê¸°"""
        return {
            "models": {
                model_id: model.to_dict() 
                for model_id, model in self.models.items()
            },
            "groups": self.model_groups,
            "metadata": {
                "default_model": self.default_model,
                "fallback_model": self.fallback_model,
                "last_updated": datetime.now().isoformat(),
                "total_models": len(self.models)
            }
        }

    def print_models_summary(self):
        """ëª¨ë¸ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ” Perplexity ëª¨ë¸ ë§¤ë‹ˆì € ìš”ì•½")
        print("=" * 50)
        
        print(f"ğŸ“Š ì´ ëª¨ë¸ ìˆ˜: {len(self.models)}")
        print(f"â­ ì¶”ì²œ ëª¨ë¸: {len(self.model_groups['recommended'])}ê°œ")
        print(f"ğŸ”§ ê¸°ë³¸ ëª¨ë¸: {self.default_model}")
        
        print("\nğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for category, models in self.model_groups.items():
            if category not in ["premium", "standard", "recommended"]:
                print(f"  â€¢ {category}: {len(models)}ê°œ")
        
        print("\nâ­ ì¶”ì²œ ëª¨ë¸ë“¤:")
        for model in self.get_recommended_models():
            print(f"  â€¢ {model.display_name}")
            print(f"    ìš©ë„: {', '.join(model.use_cases[:2])}")

    def __str__(self) -> str:
        return f"PerplexityModelManager({len(self.models)} models)"

    def __repr__(self) -> str:
        return f"PerplexityModelManager(models={list(self.models.keys())})"

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_perplexity_manager_instance = None

def get_perplexity_manager() -> PerplexityModelManager:
    """í¼í”Œë ‰ì‹œí‹° ëª¨ë¸ ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤"""
    global _perplexity_manager_instance
    if _perplexity_manager_instance is None:
        _perplexity_manager_instance = PerplexityModelManager()
    return _perplexity_manager_instance

# í¸ì˜ í•¨ìˆ˜ë“¤
def get_best_model_for_research() -> str:
    """ë¦¬ì„œì¹˜ìš© ìµœì  ëª¨ë¸"""
    return "sonar-deep-research"

def get_best_model_for_analysis() -> str:
    """ë¶„ì„ìš© ìµœì  ëª¨ë¸"""
    return "sonar-pro"

def get_best_model_for_reasoning() -> str:
    """ì¶”ë¡ ìš© ìµœì  ëª¨ë¸"""
    return "sonar-reasoning-pro"

def is_premium_model(model_id: str) -> bool:
    """í”„ë¦¬ë¯¸ì—„ ëª¨ë¸ ì—¬ë¶€"""
    manager = get_perplexity_manager()
    model = manager.get_model_info(model_id)
    return model.pricing_tier == "premium" if model else False

# ëª¨ë¸ í˜¸í™˜ì„± ì²´í¬
def check_model_compatibility(model_id: str, required_features: List[str]) -> bool:
    """ëª¨ë¸ í˜¸í™˜ì„± ê²€ì‚¬"""
    manager = get_perplexity_manager()
    model_features = manager.get_model_features(model_id)
    return all(feature in model_features for feature in required_features)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ë° ë°ëª¨
    manager = PerplexityModelManager()
    manager.print_models_summary()
    
    # ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ ì¶œë ¥
    print("\nğŸ“– ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ:")
    guide = manager.get_model_selection_guide()
    for task, info in guide.items():
        print(f"\nâ€¢ {task.replace('_', ' ').title()}:")
        print(f"  ëª¨ë¸: {info['model']}")
        print(f"  ì„¤ëª…: {info['description']}")
        print(f"  ì í•©í•œ ìš©ë„: {', '.join(info['suitable_for'])}")
